from datasets.utils import concatenate_columns, load_from_path
import anthropic
import json
import re
import pandas as pd

from argparse import ArgumentParser
from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_core.prompts import (
    FewShotChatMessagePromptTemplate,
    ChatPromptTemplate,
)
from tqdm import tqdm

load_dotenv()

DELIMITER = "\t"
CHUNK_SIZE = 3
client = anthropic.Anthropic()


def _complete_anthropic(prompt: str, system_message: str = None):
    _prompt = [
        {"role": "user", "content": prompt},
    ]
    messages = client.messages.create(
        model="claude-3-5-sonnet-20240620",
        max_tokens=4096,
        messages=_prompt,
        system=system_message,
    )
    return messages


def _format_examples(examples: list[dict]):
    input_examples = json.dumps(
        {idx: f"{ex['input']}" for idx, ex in enumerate(examples)}
    )
    output_examples = json.dumps(
        {idx: f"{ex['output']}" for idx, ex in enumerate(examples)}
    )

    return "\n\n".join([f"user: {input_examples}", f"assistant: {output_examples}"])


def _parse_response(response, columns: list) -> dict[int, dict]:
    """Returns
    {
        0: {"column1": "value1", "column2": "value2", "column3": "value3"},
    }
    """
    parsed = {}
    try:
        for idx, row_data in eval(response.content[0].text).items():
            values = row_data.split(DELIMITER)
            parsed[idx] = {col: val for col, val in zip(columns, values)}

    except SyntaxError:
        # can encounter SyntaxError when `eval`ing the response
        values = response.content[0].text.strip(" {}").split(DELIMITER)
        for idx, value in enumerate(values):
            value = re.sub(r"^\"?[0-9]+[\"\s]?:\s?", "", value.strip('"'))
            if idx // CHUNK_SIZE not in parsed:
                parsed[idx // CHUNK_SIZE] = {}
            parsed[idx // CHUNK_SIZE].update(
                {col: value for i, col in enumerate(columns) if i == idx % CHUNK_SIZE}
            )

    return parsed


def _format_chunk(chunk: pd.DataFrame, columns) -> dict[int, str]:
    """
    {
        0: "column1\tcolumn2\tcolumn3",
    }
    """
    chunk_in_format = {}
    for idx, row in chunk.iterrows():
        row_data = concatenate_columns(row, columns)
        chunk_in_format[idx] = row_data
    return json.dumps(chunk_in_format)


def translate_df(df, columns, prompt, path):
    instruct_prompt = prompt.lstrip("Human: ")
    chunks = [df.iloc[i : i + CHUNK_SIZE] for i in range(0, df.shape[0], CHUNK_SIZE)]

    with open(path, "a") as f:
        print(f"Translating {path.name}...")
        if f.tell() == 0:
            f.write(",".join(columns) + "\n")

        for chunk in tqdm(chunks):
            formatted_rows = _format_chunk(chunk, columns)
            response = _complete_anthropic(
                prompt=formatted_rows, system_message=instruct_prompt
            )
            parsed = _parse_response(response, columns)
            pd.DataFrame(parsed).T.to_csv(f, header=False, index=False)


def main(path, columns, headless):

    _examples = [
        {
            "input": DELIMITER.join(
                [
                    "In which year was the seminal Human Development Report published?",
                    "It was published in 1990.",
                ]
            ),
            "output": DELIMITER.join(
                [
                    "ì¤‘ìš”í•œ ì¸ê°„ ê°œë°œ ë³´ê³ ì„œ(Human Development Report)ëŠ” ëª‡ ë…„ë„ì— ë°œí–‰ë˜ì—ˆë‚˜ìš”?",
                    "ë³´ê³ ì„œëŠ” 1990ë…„ì— ë°œí–‰ë˜ì—ˆìŠµë‹ˆë‹¤.",
                ]
            ),
        },
        {
            "input": DELIMITER.join(
                [
                    "Sam wants to go to bed.",
                    "Tesla makes the coolest car in the world.",
                ]
            ),
            "output": DELIMITER.join(
                [
                    "ë¯¼í˜¸ëŠ” ìë ¤ê³  í•©ë‹ˆë‹¤.",
                    "ê¸°ì•„ëŠ” ì„¸ìƒì—ì„œ ê°€ì¥ ë©‹ì§„ ì°¨ë¥¼ ë§Œë“­ë‹ˆë‹¤.",
                ]
            ),
        },
    ]
    # _example_[pr]ompt = ChatPromptTemplate.from_messages(
    #     [("user", "{input}"), ("assistant", "{output}")]  # ğŸš¨ Anthropic: user/assistant
    # )

    # _few_shot_prompt = FewShotChatMessagePromptTemplate(
    #     examples=_examples,
    #     example_prompt=_example_prompt,
    # )

    _template = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ë²ˆì—­ê°€ë¡œì„œ ì˜ì–´ ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³  ìœ¤ë¬¸í•´ì•¼ í•©ë‹ˆë‹¤. ì›ë¬¸ì€ ë¬¸ì¥ ì¸ë±ìŠ¤ë³„ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ ì„ íƒì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\
    ì§ˆë¬¸ê³¼ ë‹µë³€ ì„ íƒì§€ëŠ” \tìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ìˆìœ¼ë©°, ì²« valueëŠ” ì§ˆë¬¸ì´ê³  ë‚˜ë¨¸ì§€ valueëŠ” ë‹µë³€ ì„ íƒì§€ì…ë‹ˆë‹¤. ë²ˆì—­ë¬¸ì€ ê° ë¬¸ì¥ì„ ë²ˆì—­í•œ í›„ \të¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.\
    ë‹¤ìŒ <guidelines>ì„ ì§€ì¼œ ë²ˆì—­í•˜ì„¸ìš”.

    <guidelines>
    1. ë¬¸ë§¥ì„ ë°˜ì˜í•˜ì—¬ ë²ˆì—­í•˜ì„¸ìš”. ì—¬ê¸°ì„œ ë¬¸ë§¥ì´ë€ <input>ë‚´ í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ë¬¸ì¥ ì „ì²´ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 'organism'ì€ ë¬¸ë§¥ì— ë”°ë¼ 'ìœ ê¸°ì²´, ìƒëª…ì²´, ìƒëª…, ìœ ê¸°ì  ì¡°ì§ì²´' ë“± ë‹¤ì–‘í•˜ê²Œ ë²ˆì—­ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2. ë²ˆì—­ë¬¸ì€ í•œêµ­ì–´ ì›ì–´ë¯¼ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•œêµ­ì¸ ì…ì¥ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ì´ë¤„ì ¸ì•¼ í•©ë‹ˆë‹¤. ì˜ì–´ ì›ë¬¸ì˜ ì˜ë¯¸ë¥¼ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ë˜, ì§ì—­ì´ ì–´ìƒ‰í•  ê²½ìš° ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë²ˆì—­í•˜ì„¸ìš”.
    3. 10ëŒ€ ì²­ì†Œë…„ë„ ì´í•´í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ë¬¸ì¥ì„ ìœ¤ë¬¸í•˜ì„¸ìš”. ì˜ì–´ ì›ë¬¸ì˜ í†¤ì€ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
    4. ë¬¸í™”ì  ì°¨ì´ë¥¼ ê³ ë ¤í•˜ì—¬ í•œêµ­ì–´ í‘œí˜„ì„ ì„ íƒí•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ 'kick the bucket'ì€ 'ì„¸ìƒì„ ë– ë‚˜ë‹¤'ë¡œ ë²ˆì—­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    5. ì‚¬ëŒ ì´ë¦„ì€ í•œêµ­ì‹ ì´ë¦„ìœ¼ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤. ê¸°ì—… ì´ë¦„ì€ ìœ ì‚¬ ì—…ì¢…ì˜ ê°€ì¥ ìœ ëª…í•œ í•œêµ­ ê¸°ì—…ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. 
    6. í•œêµ­ì–´ì˜ ê²©ì‹ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê²©ì‹ì²´ë€ ë‹¤ìŒê³¼ ê°™ì´ '~ìˆìŠµë‹ˆë‹¤', '~ë‹ˆë‹¤', '~í• ê¹Œìš”?' ë“±ì˜ ë¬¸ì¥ ëë§ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë§í•©ë‹ˆë‹¤.
    7. ì „ë¬¸ ìš©ì–´ë‚˜ ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì˜ì–´ ì›ë¬¸ ë‹¨ì–´ë¥¼ ì¤‘ê´„í˜¸ ì•ˆì— ë„£ì–´ ë²ˆì—­í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ 'í•­ì •ì‹ ì„± ì•½ë¬¼(Antisychotics)ì€ ...'ì™€ ê°™ì´ í‘œê¸°í•©ë‹ˆë‹¤.
    8. ë¬¸ì œ í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•  ë•ŒëŠ” ì •ë‹µì„ ì¶”ë¡ í•˜ê±°ë‚˜ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë§Œ ë²ˆì—­í•˜ê³  ì¶”ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ í•´ì„ì„ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”. ë²ˆì—­ ì‹œ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¶€ë¶„ì´ ìˆë”ë¼ë„ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
    9. ì›ë¬¸ì˜ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”. ì„ íƒì§€, ì •ë‹µ í‘œì‹œ ë“± ì›ë¬¸ì˜ êµ¬ì¡°ì  ìš”ì†Œë¥¼ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”.
    </guidelines>
    
    <examples>
    {examples}
    </examples>"""

    _few_shot_prompt = _format_examples(_examples)
    instruct_template = ChatPromptTemplate.from_template(_template)
    instruct_prompt = instruct_template.format(examples=_few_shot_prompt)

    for p in tqdm(load_from_path(path)):
        if p.suffix == ".csv":
            df = pd.read_csv(p, header=None if headless else 0)
        elif p.suffix == ".xlsx":
            df = pd.read_excel(p, header=None if headless else 0)
        if headless:
            df.columns = [str(col) for col in df.columns]
        columns = df.columns.tolist()  # use all the columns
        translate_df(df, columns, instruct_prompt, p.with_suffix(".translated.csv"))

        # # fill in missing columns
        # new_df = new_df.combine_first(df)
        # new_df.to_csv(p.with_suffix(".translated.csv"), index=False)
        import time

        time.sleep(60)


# chain = final_prompt | llm
# output = chain.invoke(
#     {
#         "input": "/t".join(
#             [
#                 "The quick brown fox jumps over the lazy dog.",
#                 "The passage was coined by Noam Chomsky.",
#             ]
#         ),
#     }
# )

if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("path", type=str)
    parser.add_argument("--headless", action="store_true")
    parser.add_argument("--columns", nargs="+")
    args = parser.parse_args()
    output = main(path=args.path, columns=args.columns, headless=args.headless)
